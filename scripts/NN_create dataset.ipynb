{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "Nt = 50\n",
    "dt = T/Nt\n",
    "x0 = 1\n",
    "y0 = 0.1\n",
    "rho_v = np.arange(0.0, 0.1, 0.01)\n",
    "alpha_v = np.arange(0.0, 0.1, 0.01)\n",
    "beta_v = np.arange(0.0, 0.1, 0.01)\n",
    "gamma_v = np.arange(0.0, 0.1, 0.01)\n",
    "delta_v = np.arange(0.0, 0.1, 0.01)\n",
    "n_tot = 4**5\n",
    "k=0\n",
    "input_list = []\n",
    "output_list =[]\n",
    "\n",
    "for rho in rho_v:\n",
    "    for alpha in alpha_v:\n",
    "        for beta in beta_v:\n",
    "            for gamma in gamma_v:\n",
    "                for delta in delta_v:\n",
    "                    k += 1\n",
    "                    # print('Advancing: '+str(k/n_tot*100)+'%')\n",
    "                    x_ex = np.zeros((Nt+1,2))\n",
    "                    tt=np.arange(0,T+dt,dt)\n",
    "                    for i,t in enumerate(tt):\n",
    "                        if i==0:\n",
    "                            x_ex[i,:] = np.array([x0,y0])\n",
    "                        else:\n",
    "                            x_ex[i,0] = x_ex[i-1,0] + dt*x_ex[i-1,0]*(alpha-beta*x_ex[i-1,1]-rho*x_ex[i-1,0])\n",
    "                            x_ex[i,1] = x_ex[i-1,1] + dt*x_ex[i-1,1]*(-gamma+delta*x_ex[i-1,0])\n",
    "                            input_list.append(x_ex[i-1,:])\n",
    "                            output_list.append(x_ex[i,:])\n",
    "\n",
    "input_train = np.array(input_list)\n",
    "output_train = np.array(output_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Flag = False\n",
    "# plot_Flag = True\n",
    "if plot_Flag:\n",
    "    np.save('../data/input_train.npy', input_train)\n",
    "    np.save('../data/output_train.npy', output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "Nt = 50\n",
    "dt = T/Nt\n",
    "x0 = 1\n",
    "y0 = 0.1\n",
    "rho_v = np.arange(0.005, 0.09, 0.01)\n",
    "alpha_v = np.arange(0.005, 0.09, 0.01)\n",
    "beta_v = np.arange(0.005, 0.09, 0.01)\n",
    "gamma_v = np.arange(0.005, 0.09, 0.01)\n",
    "delta_v = np.arange(0.005, 0.09, 0.01)\n",
    "n_tot = rho_v.shape[0]**5\n",
    "k=0\n",
    "input_list = []\n",
    "output_list =[]\n",
    "\n",
    "for rho in rho_v:\n",
    "    for alpha in alpha_v:\n",
    "        for beta in beta_v:\n",
    "            for gamma in gamma_v:\n",
    "                for delta in delta_v:\n",
    "                    k += 1\n",
    "                    # print('Advancing: '+str(k/n_tot*100)+'%')\n",
    "                    x_ex = np.zeros((Nt+1,2))\n",
    "                    tt=np.arange(0,T+dt,dt)\n",
    "                    for i,t in enumerate(tt):\n",
    "                        if i==0:\n",
    "                            x_ex[i,:] = np.array([x0,y0])\n",
    "                        else:\n",
    "                            x_ex[i,0] = x_ex[i-1,0] + dt*x_ex[i-1,0]*(alpha-beta*x_ex[i-1,1]-rho*x_ex[i-1,0])\n",
    "                            x_ex[i,1] = x_ex[i-1,1] + dt*x_ex[i-1,1]*(-gamma+delta*x_ex[i-1,0])\n",
    "                            input_list.append(x_ex[i-1,:])\n",
    "                            output_list.append(x_ex[i,:])\n",
    "\n",
    "input_test = np.array(input_list)\n",
    "output_test = np.array(output_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Flag = False\n",
    "plot_Flag = True\n",
    "if plot_Flag:\n",
    "    np.save('../data/input_test.npy', input_test)\n",
    "    np.save('../data/output_test.npy', output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from neuralop.utils import UnitGaussianNormalizer\n",
    "from neuralop.datasets.tensor_dataset import TensorDataset\n",
    "from neuralop.datasets.transforms import PositionalEmbedding\n",
    "\n",
    "\n",
    "def load_dataset(train_path, test_path,\n",
    "                batch_size, test_batch_sizes,\n",
    "                grid_boundaries=[[0,1],[0,1]],\n",
    "                positional_encoding=False,\n",
    "                encode_input=False,\n",
    "                encode_output=False,\n",
    "                encoding='pixel-wise', \n",
    "                channel_dim=1):\n",
    "    \"\"\"Loads a small Darcy-Flow dataset\n",
    "    \n",
    "    Training contains 1000 samples in resolution 16x16. \n",
    "    Testing contains 100 samples at resolution 16x16 and\n",
    "    50 samples at resolution 32x32.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_train : int\n",
    "    n_tests : int\n",
    "    batch_size : int\n",
    "    test_batch_sizes : int list\n",
    "    test_resolutions : int list, default is [16, 32],\n",
    "    grid_boundaries : int list, default is [[0,1],[0,1]],\n",
    "    positional_encoding : bool, default is True\n",
    "    encode_input : bool, default is False\n",
    "    encode_output : bool, default is True\n",
    "    encoding : 'channel-wise'\n",
    "    channel_dim : int, default is 1\n",
    "        where to put the channel dimension, defaults size is batch, channel, height, width\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    training_dataloader, testing_dataloaders\n",
    "\n",
    "    training_dataloader : torch DataLoader\n",
    "    testing_dataloaders : dict (key: DataLoader)\n",
    "    \"\"\"\n",
    "    # for res in test_resolutions:\n",
    "    #     if res not in [16, 32]:\n",
    "    #         raise ValueError(f'Only 32 and 64 are supported for test resolution, but got {test_resolutions=}')\n",
    "    # path = Path(__file__).resolve().parent.joinpath('data')\n",
    "    return load_dataset_pt(train_path, test_path, \n",
    "                         batch_size=batch_size, test_batch_size=test_batch_sizes,\n",
    "                         grid_boundaries=grid_boundaries,\n",
    "                         positional_encoding=positional_encoding,\n",
    "                         encode_input=encode_input,\n",
    "                         encode_output=encode_output,\n",
    "                         encoding=encoding,\n",
    "                         channel_dim=channel_dim)\n",
    "\n",
    "def load_dataset_pt(train_data_path, test_data_path,\n",
    "                batch_size, test_batch_size,\n",
    "                grid_boundaries=[[0,1],[0,1]],\n",
    "                positional_encoding=False,\n",
    "                encode_input=False,\n",
    "                encode_output=True,\n",
    "                encoding='channel-wise', \n",
    "                channel_dim=1):\n",
    "    \"\"\"Load the Navier-Stokes dataset\n",
    "    \"\"\"\n",
    "    data = np.load(train_data_path)\n",
    "    # n_train = data.shape[0]\n",
    "    x_train = data[:, 0]\n",
    "    y_train = data[:, 1]\n",
    "    del data\n",
    "\n",
    "    data = np.load(test_data_path)\n",
    "    # n_test = data.shape[0]\n",
    "    x_test = data[:, 0]\n",
    "    y_test = data[:, 1]\n",
    "    del data\n",
    "    \n",
    "    # if encode_input:\n",
    "    #     if encoding == 'channel-wise':\n",
    "    #         reduce_dims = list(range(x_train.ndim))\n",
    "    #     elif encoding == 'pixel-wise':\n",
    "    #         reduce_dims = [0]\n",
    "\n",
    "    #     input_encoder = UnitGaussianNormalizer(x_train, reduce_dim=reduce_dims)\n",
    "    #     x_train = input_encoder.encode(x_train)\n",
    "    #     x_test = input_encoder.encode(x_test.contiguous())\n",
    "    # else:\n",
    "    #     input_encoder = None\n",
    "\n",
    "    # if encode_output:\n",
    "    #     if encoding == 'channel-wise':\n",
    "    #         reduce_dims = list(range(y_train.ndim))\n",
    "    #     elif encoding == 'pixel-wise':\n",
    "    #         reduce_dims = [0]\n",
    "\n",
    "    #     output_encoder = UnitGaussianNormalizer(y_train, reduce_dim=reduce_dims)\n",
    "    #     y_train = output_encoder.encode(y_train)\n",
    "    # else:\n",
    "    #     output_encoder = None\n",
    "    output_encoder = None\n",
    "\n",
    "    train_db = TensorDataset(x_train, y_train, transform_x=PositionalEmbedding(grid_boundaries, 0) if positional_encoding else None)\n",
    "    train_loader = torch.utils.data.DataLoader(train_db,\n",
    "                                            batch_size=batch_size, shuffle=True,\n",
    "                                            num_workers=0, pin_memory=True, persistent_workers=False)\n",
    "\n",
    "    test_db = TensorDataset(x_test, y_test,transform_x=PositionalEmbedding(grid_boundaries, 0) if positional_encoding else None)\n",
    "    test_loader = torch.utils.data.DataLoader(test_db,\n",
    "                                              batch_size=test_batch_size, shuffle=False,\n",
    "                                              num_workers=0, pin_memory=True, persistent_workers=False)\n",
    "    test_loaders =  {'1': test_loader}\n",
    "    # for ( n_test, test_batch_size) in zip(n_test, test_batch_sizes):\n",
    "    #     print(f'Loading test db with {n_test} samples and batch-size={test_batch_size}')\n",
    "    #     data = torch.load(Path(data_path).joinpath(f'darcy_test_{res}.pt').as_posix())\n",
    "    #     x_test = data['x'][:n_test, :, :].unsqueeze(channel_dim).type(torch.float32).clone()\n",
    "    #     y_test = data['y'][:n_test, :, :].unsqueeze(channel_dim).clone()\n",
    "    #     del data \n",
    "    #     if input_encoder is not None:\n",
    "    #         x_test = input_encoder.encode(x_test)\n",
    "\n",
    "    #     test_db = TensorDataset(x_test, y_test, transform_x=PositionalEmbedding(grid_boundaries, 0) if positional_encoding else None)\n",
    "    #     test_loader = torch.utils.data.DataLoader(test_db,\n",
    "    #                                               batch_size=test_batch_size, shuffle=False,\n",
    "    #                                               num_workers=0, pin_memory=True, persistent_workers=False)\n",
    "    #     test_loaders[res] = test_loader\n",
    "\n",
    "    return train_loader, test_loaders, output_encoder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
